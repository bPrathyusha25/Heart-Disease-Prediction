# Heart-Disease-Prediction
Heart disease can be managed effectively with a combination of lifestyle changes, medicine and, in some cases, surgery. With the right treatment, the symptoms of heart disease can be reduced and the functioning of the heart improved. The predicted results can be used to prevent and thus reduce cost for surgical treatment and other expensive.


![image](https://user-images.githubusercontent.com/105341413/206938566-ac6d21a3-a7c3-46bb-a984-35f0bcffc530.png)


The overall objective of our work will be to predict accurately with few tests and attributes the presence of heart disease. Attributes considered form the primary basis for tests and give accurate results more or less. Many more input attributes can be taken but our goal is to predict with few attributes and faster efficiency the risk of having heart disease. Decisions are often made based on doctors’ intuition and experience rather than on the knowledge rich data hidden in the data set and databases.



This practice leads to unwanted biases, errors and excessive medical costs which affects the quality of service provided to patients
In many nations, cardiovascular disease is the main cause of death. 
Cardiovascular illness is frequently identified by doctors based on the results of recent clinical testing and their prior experience treating patients who presented with comparable symptoms. Heart disease patients need an immediate diagnosis, prompt treatment, and ongoing monitoring. 
Numerous data mining techniques have been applied in the past to diagnose and predict heart illnesses in order to meet their needs. 
A little emphasis was placed on determining the strength of these features in earlier research, which also concentrated on identifying the main contributing aspects to heart disease prediction.


#Data Understanding

We have used a variety of tools, including Numpy, Pandas, Matplotlib, and Seaborn, to import the data from the data collection. We read the dataset after loading the data. 

![image](https://user-images.githubusercontent.com/105341413/206939142-247f2dff-e1b6-4280-88c2-2f3524d2f3c4.png)


# Data Evaluation

We go through numerous stages during the evaluation process, including:
By performing multiple analyses on the raw csv file using different software programs and uploading the data to Jupiter notebook, we can anticipate the output value (class).
After modeling each method, we calculated the four models' accuracy ratings. Of the three models, Random Forest has the best accuracy rating (90.16%), followed by Logistic Regression (85.25%). Decision trees, with an accuracy rate of 81.97%, had the lowest accuracy rate.


![image](https://user-images.githubusercontent.com/105341413/206939097-51473001-a30a-4daa-a222-254bb8c26a03.png)
